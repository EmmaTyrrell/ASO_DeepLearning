# -*- coding: utf-8 -*-
"""ASOML_FinalProject_ET.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q8clRusNGqgRljROboRDcrFIwooeIb3i

Emma Tyrrell,

Working on a CNN to predict SWE with several input features (10) and swe.
"""

# import modules
import os
import sys
import pandas
import rasterio
import numpy as np
import geopandas
import tensorflow as tf
import random
import seaborn as sns
import math
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.model_selection import train_test_split
from rasterio.windows import from_bounds
from keras.models import load_model
from shapely.geometry import box
from rasterio.mask import mask
from rasterio.windows import from_bounds
from keras.utils import to_categorical
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten, Lambda, Activation
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Dense, BatchNormalization, Activation, Input, Add
from keras.callbacks import EarlyStopping, ModelCheckpoint
# keras.layers.normalization import BatchNormalization
from keras.layers import BatchNormalization
from contextlib import redirect_stdout

print("modules imported")

# mount drive to get access to the sampled training data and sampled features to plot them
# from google.colab import drive
# drive.mount('/content/drive')
# print("drive mounted")

# set paths for sampled training and sampled features and outputs
root = "/pl/active/hydroServer/ASO_DeepLearningData/"
sampledTraining = root + "Training_TestingData/target_splits/V2/"
sampledFeatures = root + "clipped_features/"
outFigures = root + "output_figures/"
features = root + "feature_rasters/scaled/"

from datetime import datetime

now = datetime.now()
now_format = now.strftime("%Y-%m-%d_%H:%M:%S")
outText = root + f"outText/QC_CNN_v2.txt"

file = open(outText, "a")
sys.stdout = file
print("STARTING MODEL ANALYSIS")
print("")

"""# Processing Features and Targets
The next step is to take the targets and the features and organize them into numpy arrays for data storage.

The target is a SWE dataset on a 128x128 dimension. This is the first dataset that is looped through. Once the the raster of the target dataset is opened, the bounds of that raster is used to get the associated values of the feautres. I think flatten the SWE raster and then add it to a 2d array.  



There are two sets of feature data. First is the terriain varaibles that are static variables. The second are vegatation variables which is one variable for each year. Both of these folders with the respective terrain variables are looped through to create a an array that is the same shape and location as the corresponding target.



"""

# processing training data
print("*** Processing Training Data ***")
featureArray = []
targetArray = []
years = list(range(2013, 2025))
for year in years:
    print(f"Processing year: {year}")

    # loop through SWE
    trainingDataSet = f"{sampledTraining}/{year}/outSplits_v2/"
    for training in os.listdir(trainingDataSet):
      featureTuple = ()
      featureName = []
      if training.endswith(".tif"):
          # loop though the phv variables
          with rasterio.open(trainingDataSet + training) as train_src:
              train_data = train_src.read(1)
              meta = train_src.meta.copy()
              train_extent = train_src.bounds
              train_transform = train_src.transform
              train_crs = train_src.crs

              # apply a mask
              mask = train_data > 0
              masked_target = np.where(mask, train_data, -1)

              target_flat = masked_target.flatten()
              targetArray.append(target_flat)

      # targetName.append("SWE")
      for feature in os.listdir(features):
          if feature.endswith(".tif"):
              featureName.append(feature[:-4])
              with rasterio.open(features + feature) as chan_src:
                  window = from_bounds(*train_extent, transform=chan_src.transform)
                  chan_src_data = chan_src.read(1, window=window)
                  featureTuple += (chan_src_data,)

      vegLayers = features + "/forest_scaled/"
      for veg in os.listdir(vegLayers):
          if veg.endswith(".tif"):
              if veg.startswith(str(year)):
                  featureName.append(veg[:-4])
                  with rasterio.open(vegLayers + veg) as veg_src:
                      window = from_bounds(*train_extent, transform=veg_src.transform)
                      veg_src_data = veg_src.read(1, window=window)
                      featureTuple += (veg_src_data,)

      feature_stack = np.dstack(featureTuple)
      featureArray.append(feature_stack)

X = np.array(featureArray)
y = np.array(targetArray)

# printing shapes of features and targets
print(" ")
print(f"shape of features: {X.shape}")
print(f"shape of targets: {y.shape}")
print(f"data type of targets: {X.dtype}")
print(f"data type of targets: {y.dtype}")

# split ratio
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True)
print(" ")
print("________________________________ Training and Validation Data Shapes ________________________________")
print("Training data shape:", X_train.shape, y_train.shape)
print("Validation data shape:", X_valid.shape, y_valid.shape)
print("***")

"""### Preparing the Test Data

"""

# define this function in order to parse out the training and validation data
def testing_data_pairs(GroupFolderRoot, GroupNumber, year, train_or_test, featureFolder, vegetationFolder):
    featureArray = []
    targetArray = []
    year = year
    targetFolder = f"{GroupFolderRoot}/V2/Group{GroupNumber}/{train_or_test}/"
    for training in os.listdir(targetFolder):
      featureTuple = ()
      featureName = []
      if training.endswith(".tif"):
          # loop though the phv variables
          with rasterio.open(targetFolder + training) as train_src:
              train_data = train_src.read(1)
              meta = train_src.meta.copy()
              train_extent = train_src.bounds
              train_transform = train_src.transform
              train_crs = train_src.crs
              shape_target = train_data.shape

              mask = train_data > 0
              masked_target = np.where(mask, train_data, -1)

              target_flat = masked_target.flatten()
              targetArray.append(target_flat)


      for feature in os.listdir(featureFolder):
          if feature.endswith(".tif"):
              featureName.append(feature[:-4])
              with rasterio.open(featureFolder + feature) as chan_src:
                  window = from_bounds(*train_extent, transform=chan_src.transform)
                  chan_src_data = chan_src.read(1, window=window)
                  featureTuple += (chan_src_data,)

      for veg in os.listdir(vegetationFolder):
          if veg.endswith(".tif"):
              if veg.startswith(str(year)):
                  featureName.append(veg[:-4])
                  with rasterio.open(vegetationFolder + veg) as veg_src:
                       window = from_bounds(*train_extent, transform=veg_src.transform)
                       veg_src_data = veg_src.read(1, window=window)
                       featureTuple += (veg_src_data,)

      feature_stack = np.dstack(featureTuple)
      featureArray.append(feature_stack)

    return np.array(featureArray), np.array(targetArray)

# group training shapes
# Group 1
X_train_G1, y_train_G1 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="1", year=2022, train_or_test="train", featureFolder=features, vegetationFolder=features + "/forest_scaled/")
X_test_G1, y_test_G1 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="1", year=2022, train_or_test="test", featureFolder=features, vegetationFolder=features + "/forest_scaled/")

# Group 2
X_train_G2, y_train_G2 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="2", year=2023, train_or_test="train", featureFolder=features, vegetationFolder=features + "/forest_scaled/")
X_test_G2, y_test_G2 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="2", year=2023, train_or_test="test", featureFolder=features, vegetationFolder=features + "/forest_scaled/")

# Group 3
X_train_G3, y_train_G3 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="3", year=2023, train_or_test="train", featureFolder=features, vegetationFolder=features + "/forest_scaled/")
X_test_G3, y_test_G3 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="3", year=2023, train_or_test="test", featureFolder=features, vegetationFolder=features + "/forest_scaled/")

#Group 4
X_train_G4, y_train_G4 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="4", year=2023, train_or_test="train", featureFolder=features, vegetationFolder=features + "/forest_scaled/")
X_test_G4, y_test_G4 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="4", year=2023, train_or_test="test", featureFolder=features, vegetationFolder=features + "/forest_scaled/")

# Group5
X_train_G5, y_train_G5 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="5", year=2024, train_or_test="train", featureFolder=features, vegetationFolder=features + "/forest_scaled/")
X_test_G5, y_test_G5 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="5", year=2024, train_or_test="test", featureFolder=features, vegetationFolder=features + "/forest_scaled/")

# Group6
X_train_G6, y_train_G6 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="6", year=2023, train_or_test="train", featureFolder=features, vegetationFolder=features + "/forest_scaled/")
X_test_G6, y_test_G6 = testing_data_pairs(GroupFolderRoot=root + "Training_TestingData/test_splits/", GroupNumber="6", year=2023, train_or_test="test", featureFolder=features, vegetationFolder=features + "/forest_scaled/")

print(" ")
print("________________________________ Training and Test Data Shapes for all Testing Groups ________________________________")
print(" ")
print("** Group 1 ** ")
print("Training data shape:", X_train_G1.shape, y_train_G1.shape)
print("Test data shape:", X_test_G1.shape, y_test_G1.shape)
print(" ")
print("** Group 2 ** ")
print("Training data shape:", X_train_G2.shape, y_train_G2.shape)
print("Test data shape:", X_test_G2.shape, y_test_G2.shape)
print(" ")
print("** Group 3 ** ")
print("Training data shape:", X_train_G3.shape, y_train_G3.shape)
print("Test data shape:", X_test_G3.shape, y_test_G3.shape)
print(" ")
print("** Group 4 ** ")
print("Training data shape:", X_train_G4.shape, y_train_G4.shape)
print("Test data shape:", X_test_G4.shape, y_test_G4.shape)
print(" ")
print("** Group 5 ** ")
print("Training data shape:", X_train_G5.shape, y_train_G5.shape)
print("Test data shape:", X_test_G5.shape, y_test_G5.shape)
print(" ")
print("** Group 6 ** ")
print("Training data shape:", X_train_G6.shape, y_train_G6.shape)
print("Test data shape:", X_test_G6.shape, y_test_G6.shape)

"""# Building the Standard CNN Model
This next step is building a standard base model to compare against the test dataset (which will be discusssed later).
"""

# first I'm going to set up a directory to output all the models for the separate models
modelFolder = "/CNN_v2_mask/"
os.makedirs(outFigures + modelFolder, exist_ok=True)
outFigures = root + "output_figures" + modelFolder
outBestModel = outFigures + "best_SWE_model.keras"

# Build Network
model = Sequential()
model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(128, 128, 10), padding='valid'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))

# add stacked convolutions
model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='valid'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))

model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='valid'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))

model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='valid'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))

model.add(Flatten())
model.add(Dropout(0.1))

# dense layer
model.add(Dense(1024, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.1))
# output layer
model.add(Dense(16384, activation='linear'))

# created a function do not could loss for tthe masked values
from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError
from tensorflow.keras.utils import register_keras_serializable
from keras.callbacks import EarlyStopping, ModelCheckpoint

@register_keras_serializable()
def masked_loss_fn(y_true, y_pred, loss_fn, mask_value=-1):
    mask = tf.not_equal(y_true, mask_value)
    y_true_masked = tf.boolean_mask(y_true, mask)
    y_pred_masked = tf.boolean_mask(y_pred, mask)
    # calc the loss
    return loss_fn(y_true_masked, y_pred_masked)

@register_keras_serializable()
def masked_mse(y_true, y_pred):
    return masked_loss_fn(y_true, y_pred, tf.keras.losses.MeanSquaredError())

@register_keras_serializable()
def masked_mae(y_true, y_pred):
    return masked_loss_fn(y_true, y_pred, tf.keras.losses.MeanAbsoluteError())


try:
    from tensorflow.keras.utils import plot_model

    # create a diagram from the model
    plot_model(model, to_file=(outFigures + 'model_diagram.png'), show_shapes=True, show_layer_names=True)
except Exception as ex:
    print(ex)
# build in early stops
early_stopping = EarlyStopping(monitor="val_loss", mode='min', verbose=1, patience=10)

# build in check points to save the best model
checkpoint = ModelCheckpoint(outBestModel, monitor="val_loss", verbose=1, save_best_only=True, mode='min')

# compile model
model.compile(optimizer='adam', loss=masked_mse, metrics=[masked_mae, masked_mse])

# print out model summary
model.summary()

# run model
print('Running model 1... ')
print("________________________________ Model 1 Fitting ________________________________")
history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, callbacks=[early_stopping, checkpoint],
                    validation_data=(X_valid, y_valid))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.savefig(os.path.join(outFigures, "model_loss_v2.png"))
plt.show()

plt.plot(history.history['masked_mse'])
plt.plot(history.history['val_masked_mse'])
plt.title('Model MSE')
plt.ylabel('Masked MSE')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.savefig(os.path.join(outFigures, "model_mse_v2.png"))
plt.show()

plt.plot(history.history['masked_mae'])
plt.plot(history.history['val_masked_mae'])
plt.title('Model MAE')
plt.ylabel('Masked MAE')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.savefig(os.path.join(outFigures, "model_mae_v2.png"))
plt.show()

"""## Testing the Model on Test Data

### Testing Group 1
"""

print("________________________________ Analyzing All Testing Groups ________________________________")
# now we test the data on the Group one on the saved model\from keras.models import load_model
from keras.models import load_model
from sklearn.metrics import mean_squared_error, mean_absolute_error
from matplotlib.colors import ListedColormap, BoundaryNorm

# load model
saved_model = load_model(outBestModel, custom_objects={'masked_mse': masked_mse, 'masked_mae': masked_mae,
                                                       'masked_loss_fn': masked_loss_fn})
# evaulate model
trainG1_eval = saved_model.evaluate(X_train_G1, y_train_G1)
testG1_eval = saved_model.evaluate(X_test_G1, y_test_G1, verbose=0)

# extract mae
trainG1_mae = trainG1_eval[1]
testG1_mae = testG1_eval[1]
trainG1_mse = trainG1_eval[2]
testG1_mse = testG1_eval[2]
print(" ")
print("***GROUP 1***")
print('Group 1: Masked Training MAE: %.3f, Masked Testing MAE: %.3f' % (trainG1_mae, testG1_mae))
print('Group 1: Masked Training MSE: %.3f, Masked Testing MSE: %.3f' % (trainG1_mse, testG1_mse))
print('Group 1: Masked Training RMSE: %.3f, Masked Testing RMSE: %.3f' %
      (np.sqrt(trainG1_mse), np.sqrt(testG1_mse)))

# predicting test labels using the best model
preds = saved_model.predict(X_test_G1, verbose=1)
print(preds.shape)

# plot out
selected_indices = [5, 35, 50]
reshaped_preds = preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G1.reshape((-1, 128, 128))
reshaped_preds = np.nan_to_num(reshaped_preds, nan=0, posinf=0, neginf=0)
reshaped_y_test = np.nan_to_num(reshaped_y_test, nan=0, posinf=0, neginf=0)

# check shapes
print("y_test_G1 shape:", y_test_G1.shape)
print("preds shape:", preds.shape)
mask = (y_test_G1[:preds.shape[0]] == -1)

# apply the mask to predictions
masked_preds = np.where(mask, -1, preds)

# reshaping and plotting
reshaped_preds = masked_preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G1[:preds.shape[0]].reshape((-1, 128, 128))

# plot
colors = ["white"] + plt.cm.viridis(np.linspace(0, 1, 256)).tolist()
custom_cmap = ListedColormap(colors)

# boundaries for the colormap
vmin = 0
vmax = 3
bounds = [0] + list(np.linspace(0, vmax, 256))
norm = BoundaryNorm(bounds, custom_cmap.N)

# visualize the selected samples
fig, axes = plt.subplots(len(selected_indices), 2, figsize=(8, 8))  # Adjust for 3 samples

for i, idx in enumerate(selected_indices):
    pred_sample = reshaped_preds[idx]
    real_sample = reshaped_y_test[idx]

    # Display predicted and real samples with custom colormap
    im_pred = axes[i, 0].imshow(pred_sample, cmap=custom_cmap, norm=norm)
    axes[i, 0].set_title(f"Prediction {idx}")
    axes[i, 0].axis('off')

    im_real = axes[i, 1].imshow(real_sample, cmap=custom_cmap, norm=norm)
    axes[i, 1].set_title(f"Ground Truth {idx}")
    axes[i, 1].axis('off')

# colorbar for the entire figure
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
fig.colorbar(im_pred, cax=cbar_ax)
fig.suptitle("Comparison of Predictions and Ground Truth for Group 1", fontsize=12, y=0.95)

plt.tight_layout(rect=[0, 0, 0.9, 0.9])
plt.savefig(os.path.join(outFigures, "Preds_GroundTruth_Group1_v2.png"))
plt.show()

"""### Testing Group 2"""

# evaulate model
trainG2_eval = saved_model.evaluate(X_train_G2, y_train_G2)
testG2_eval = saved_model.evaluate(X_test_G2, y_test_G2, verbose=0)

# extract mae
trainG2_mae = trainG2_eval[1]
testG2_mae = testG2_eval[1]
trainG2_mse = trainG2_eval[2]
testG2_mse = testG2_eval[2]
print(" ")
print("***GROUP 2***")
print('Group 2: Masked Training MAE: %.3f, Masked Testing MAE: %.3f' % (trainG2_mae, testG2_mae))
print('Group 2: Masked Training MSE: %.3f, Masked Testing MSE: %.3f' % (trainG2_mse, testG2_mse))
print('Group 2: Masked Training RMSE: %.3f, Masked Testing RMSE: %.3f' %
      (np.sqrt(trainG2_mse), np.sqrt(testG2_mse)))

# predicting test labels using the best model
preds = saved_model.predict(X_test_G2, verbose=1)
print(preds.shape)

# plot out
selected_indices = [5, 12, 80]
reshaped_preds = preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G2.reshape((-1, 128, 128))
reshaped_preds = np.nan_to_num(reshaped_preds, nan=0, posinf=0, neginf=0)
reshaped_y_test = np.nan_to_num(reshaped_y_test, nan=0, posinf=0, neginf=0)

# check shapes
print("y_test_G2 shape:", y_test_G2.shape)
print("preds shape:", preds.shape)
mask = (y_test_G2[:preds.shape[0]] == -1)

# apply the mask to predictions
masked_preds = np.where(mask, -1, preds)

# reshaping and plotting
reshaped_preds = masked_preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G2[:preds.shape[0]].reshape((-1, 128, 128))

# plot
colors = ["white"] + plt.cm.viridis(np.linspace(0, 1, 256)).tolist()
custom_cmap = ListedColormap(colors)

# boundaries for the colormap
vmin = 0
vmax = 3
bounds = [0] + list(np.linspace(0, vmax, 256))
norm = BoundaryNorm(bounds, custom_cmap.N)

# visualize the selected samples
fig, axes = plt.subplots(len(selected_indices), 2, figsize=(8, 8))  # Adjust for 3 samples

for i, idx in enumerate(selected_indices):
    pred_sample = reshaped_preds[idx]
    real_sample = reshaped_y_test[idx]

    # Display predicted and real samples with custom colormap
    im_pred = axes[i, 0].imshow(pred_sample, cmap=custom_cmap, norm=norm)
    axes[i, 0].set_title(f"Prediction {idx}")
    axes[i, 0].axis('off')

    im_real = axes[i, 1].imshow(real_sample, cmap=custom_cmap, norm=norm)
    axes[i, 1].set_title(f"Ground Truth {idx}")
    axes[i, 1].axis('off')

# colorbar for the entire figure
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
fig.colorbar(im_pred, cax=cbar_ax)
fig.suptitle("Comparison of Predictions and Ground Truth for Group 2", fontsize=12, y=0.95)

plt.tight_layout(rect=[0, 0, 0.9, 0.9])
plt.savefig(os.path.join(outFigures, "Preds_GroundTruth_Group2_v2.png"))
plt.show()

"""### Testing Group 3"""

# evaulate model
trainG3_eval = saved_model.evaluate(X_train_G3, y_train_G3)
testG3_eval = saved_model.evaluate(X_test_G3, y_test_G3, verbose=0)

# extract mae
trainG3_mae = trainG3_eval[1]
testG3_mae = testG3_eval[1]
trainG3_mse = trainG3_eval[2]
testG3_mse = testG3_eval[2]
print(" ")
print("***GROUP 3***")
print('Group 3: Masked Training MAE: %.3f, Masked Testing MAE: %.3f' % (trainG3_mae, testG3_mae))
print('Group 3: Masked Training MSE: %.3f, Masked Testing MSE: %.3f' % (trainG3_mse, testG3_mse))
print('Group 3: Masked Training RMSE: %.3f, Masked Testing RMSE: %.3f' %
      (np.sqrt(trainG3_mse), np.sqrt(testG3_mse)))

# predicting test labels using the best model
preds = saved_model.predict(X_test_G3, verbose=1)
print(preds.shape)

# plot out
selected_indices = [45, 85, 15]
reshaped_preds = preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G3.reshape((-1, 128, 128))
reshaped_preds = np.nan_to_num(reshaped_preds, nan=0, posinf=0, neginf=0)
reshaped_y_test = np.nan_to_num(reshaped_y_test, nan=0, posinf=0, neginf=0)

# check shapes
print("y_test_G3 shape:", y_test_G3.shape)
print("preds shape:", preds.shape)
mask = (y_test_G3[:preds.shape[0]] == -1)

# apply the mask to predictions
masked_preds = np.where(mask, -1, preds)

# reshaping and plotting
reshaped_preds = masked_preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G3[:preds.shape[0]].reshape((-1, 128, 128))

# plot
colors = ["white"] + plt.cm.viridis(np.linspace(0, 1, 256)).tolist()
custom_cmap = ListedColormap(colors)

# boundaries for the colormap
vmin = 0
vmax = 3
bounds = [0] + list(np.linspace(0, vmax, 256))
norm = BoundaryNorm(bounds, custom_cmap.N)

# visualize the selected samples
fig, axes = plt.subplots(len(selected_indices), 2, figsize=(8, 8))  # Adjust for 3 samples

for i, idx in enumerate(selected_indices):
    pred_sample = reshaped_preds[idx]
    real_sample = reshaped_y_test[idx]

    # Display predicted and real samples with custom colormap
    im_pred = axes[i, 0].imshow(pred_sample, cmap=custom_cmap, norm=norm)
    axes[i, 0].set_title(f"Prediction {idx}")
    axes[i, 0].axis('off')

    im_real = axes[i, 1].imshow(real_sample, cmap=custom_cmap, norm=norm)
    axes[i, 1].set_title(f"Ground Truth {idx}")
    axes[i, 1].axis('off')

# colorbar for the entire figure
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
fig.colorbar(im_pred, cax=cbar_ax)
fig.suptitle("Comparison of Predictions and Ground Truth for Group 3", fontsize=12, y=0.95)

plt.tight_layout(rect=[0, 0, 0.9, 0.9])
plt.savefig(os.path.join(outFigures, "Preds_GroundTruth_Group3.png"))
plt.show()

"""### Testing Group 4"""

# evaulate model
trainG4_eval = saved_model.evaluate(X_train_G4, y_train_G4)
testG4_eval = saved_model.evaluate(X_test_G4, y_test_G4, verbose=0)

# extract mae
trainG4_mae = trainG4_eval[1]
testG4_mae = testG4_eval[1]
trainG4_mse = trainG4_eval[2]
testG4_mse = testG4_eval[2]
print(" ")
print("***GROUP 4***")
print('Group 4: Masked Training MAE: %.3f, Masked Testing MAE: %.3f' % (trainG4_mae, testG4_mae))
print('Group 4: Masked Training MSE: %.3f, Masked Testing MSE: %.3f' % (trainG4_mse, testG4_mse))
print('Group 4: Masked Training RMSE: %.3f, Masked Testing RMSE: %.3f' %
      (np.sqrt(trainG4_mse), np.sqrt(testG4_mse)))

# predicting test labels using the best model
preds = saved_model.predict(X_test_G4, verbose=1)
print(preds.shape)

# plot out
selected_indices = [45, 115, 140]
reshaped_preds = preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G4.reshape((-1, 128, 128))
reshaped_preds = np.nan_to_num(reshaped_preds, nan=0, posinf=0, neginf=0)
reshaped_y_test = np.nan_to_num(reshaped_y_test, nan=0, posinf=0, neginf=0)

# check shapes
print("y_test_G4 shape:", y_test_G4.shape)
print("preds shape:", preds.shape)
mask = (y_test_G4[:preds.shape[0]] == -1)

# apply the mask to predictions
masked_preds = np.where(mask, -1, preds)

# reshaping and plotting
reshaped_preds = masked_preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G4[:preds.shape[0]].reshape((-1, 128, 128))

# plot
colors = ["white"] + plt.cm.viridis(np.linspace(0, 1, 256)).tolist()
custom_cmap = ListedColormap(colors)

# boundaries for the colormap
vmin = 0
vmax = 3
bounds = [0] + list(np.linspace(0, vmax, 256))
norm = BoundaryNorm(bounds, custom_cmap.N)

# visualize the selected samples
fig, axes = plt.subplots(len(selected_indices), 2, figsize=(8, 8))  # Adjust for 3 samples

for i, idx in enumerate(selected_indices):
    pred_sample = reshaped_preds[idx]
    real_sample = reshaped_y_test[idx]

    # Display predicted and real samples with custom colormap
    im_pred = axes[i, 0].imshow(pred_sample, cmap=custom_cmap, norm=norm)
    axes[i, 0].set_title(f"Prediction {idx}")
    axes[i, 0].axis('off')

    im_real = axes[i, 1].imshow(real_sample, cmap=custom_cmap, norm=norm)
    axes[i, 1].set_title(f"Ground Truth {idx}")
    axes[i, 1].axis('off')

# colorbar for the entire figure
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
fig.colorbar(im_pred, cax=cbar_ax)
fig.suptitle("Comparison of Predictions and Ground Truth for Group 4", fontsize=12, y=0.95)

plt.tight_layout(rect=[0, 0, 0.9, 0.9])
plt.savefig(os.path.join(outFigures, "Preds_GroundTruth_Group4_v2.png"))
plt.show()

"""### Training Group 5"""

# evaulate model
trainG5_eval = saved_model.evaluate(X_train_G5, y_train_G5)
testG5_eval = saved_model.evaluate(X_test_G5, y_test_G5, verbose=0)

# extract mae
trainG5_mae = trainG5_eval[1]
testG5_mae = testG5_eval[1]
trainG5_mse = trainG5_eval[2]
testG5_mse = testG5_eval[2]
print(" ")
print("***GROUP 5***")
print('Group 5: Masked Training MAE: %.3f, Masked Testing MAE: %.3f' % (trainG5_mae, testG5_mae))
print('Group 5: Masked Training MSE: %.3f, Masked Testing MSE: %.3f' % (trainG5_mse, testG5_mse))
print('Group 5: Masked Training RMSE: %.3f, Masked Testing RMSE: %.3f' %
      (np.sqrt(trainG5_mse), np.sqrt(testG5_mse)))

# predicting test labels using the best model
preds = saved_model.predict(X_test_G5, verbose=1)
print(preds.shape)

# plot out
selected_indices = [10, 60, 70]
reshaped_preds = preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G5.reshape((-1, 128, 128))
reshaped_preds = np.nan_to_num(reshaped_preds, nan=0, posinf=0, neginf=0)
reshaped_y_test = np.nan_to_num(reshaped_y_test, nan=0, posinf=0, neginf=0)

# check shapes
print("y_test_G5 shape:", y_test_G5.shape)
print("preds shape:", preds.shape)
mask = (y_test_G5[:preds.shape[0]] == -1)

# apply the mask to predictions
masked_preds = np.where(mask, -1, preds)

# reshaping and plotting
reshaped_preds = masked_preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G5[:preds.shape[0]].reshape((-1, 128, 128))

# plot
colors = ["white"] + plt.cm.viridis(np.linspace(0, 1, 256)).tolist()
custom_cmap = ListedColormap(colors)

# boundaries for the colormap
vmin = 0
vmax = 3
bounds = [0] + list(np.linspace(0, vmax, 256))
norm = BoundaryNorm(bounds, custom_cmap.N)

# visualize the selected samples
fig, axes = plt.subplots(len(selected_indices), 2, figsize=(8, 8))  # Adjust for 3 samples

for i, idx in enumerate(selected_indices):
    pred_sample = reshaped_preds[idx]
    real_sample = reshaped_y_test[idx]

    # Display predicted and real samples with custom colormap
    im_pred = axes[i, 0].imshow(pred_sample, cmap=custom_cmap, norm=norm)
    axes[i, 0].set_title(f"Prediction {idx}")
    axes[i, 0].axis('off')

    im_real = axes[i, 1].imshow(real_sample, cmap=custom_cmap, norm=norm)
    axes[i, 1].set_title(f"Ground Truth {idx}")
    axes[i, 1].axis('off')

# colorbar for the entire figure
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
fig.colorbar(im_pred, cax=cbar_ax)
fig.suptitle("Comparison of Predictions and Ground Truth for Group 5", fontsize=12, y=0.95)

plt.tight_layout(rect=[0, 0, 0.9, 0.9])
plt.savefig(os.path.join(outFigures, "Preds_GroundTruth_Group5_v2.png"))
plt.show()

"""### Testing Group 6"""

# evaulate model
from matplotlib.colors import BoundaryNorm, ListedColormap

trainG6_eval = saved_model.evaluate(X_train_G6, y_train_G6)
testG6_eval = saved_model.evaluate(X_test_G6, y_test_G6, verbose=0)

# extract mae
trainG6_mae = trainG6_eval[1]
testG6_mae = testG6_eval[1]
trainG6_mse = trainG6_eval[2]
testG6_mse = testG6_eval[2]
print(" ")
print("***GROUP 6***")
print('Group 6: Masked Training MAE: %.3f, Masked Testing MAE: %.3f' % (trainG6_mae, testG6_mae))
print('Group 6: Masked Training MSE: %.3f, Masked Testing MSE: %.3f' % (trainG6_mse, testG6_mse))
print('Group 6: Masked Training RMSE: %.3f, Masked Testing RMSE: %.3f' %
      (np.sqrt(trainG6_mse), np.sqrt(testG6_mse)))

# predicting test labels using the best model
preds = saved_model.predict(X_test_G6, verbose=1)
print(preds.shape)

# plot out the preds and the samples
selected_indices = [10, 30, 45]
reshaped_preds = preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G6.reshape((-1, 128, 128))
reshaped_preds = np.nan_to_num(reshaped_preds, nan=0, posinf=0, neginf=0)
reshaped_y_test = np.nan_to_num(reshaped_y_test, nan=0, posinf=0, neginf=0)

# check shapes
print("y_test_G6 shape:", y_test_G6.shape)
print("preds shape:", preds.shape)
mask = (y_test_G6[:preds.shape[0]] == -1)

# apply the mask to predictions
masked_preds = np.where(mask, -1, preds)

# reshaping and plotting
reshaped_preds = masked_preds.reshape((-1, 128, 128))
reshaped_y_test = y_test_G6[:preds.shape[0]].reshape((-1, 128, 128))

# plot
colors = ["white"] + plt.cm.viridis(np.linspace(0, 1, 256)).tolist()
custom_cmap = ListedColormap(colors)

# boundaries for the colormap
vmin = 0
vmax = 3
bounds = [0] + list(np.linspace(0, vmax, 256))
norm = BoundaryNorm(bounds, custom_cmap.N)

# visualize the selected samples
fig, axes = plt.subplots(len(selected_indices), 2, figsize=(8, 8))  # Adjust for 3 samples

for i, idx in enumerate(selected_indices):
    pred_sample = reshaped_preds[idx]
    real_sample = reshaped_y_test[idx]

    # Display predicted and real samples with custom colormap
    im_pred = axes[i, 0].imshow(pred_sample, cmap=custom_cmap, norm=norm)
    axes[i, 0].set_title(f"Prediction {idx}")
    axes[i, 0].axis('off')

    im_real = axes[i, 1].imshow(real_sample, cmap=custom_cmap, norm=norm)
    axes[i, 1].set_title(f"Ground Truth {idx}")
    axes[i, 1].axis('off')

# colorbar for the entire figure
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
fig.colorbar(im_pred, cax=cbar_ax)
fig.suptitle("Comparison of Predictions and Ground Truth for Group 6", fontsize=12, y=0.95)

plt.tight_layout(rect=[0, 0, 0.9, 0.9])
plt.savefig(os.path.join(outFigures, "Preds_GroundTruth_Group6_v2.png"))
plt.show()
